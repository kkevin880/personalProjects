{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootcamp I Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.6/site-packages (1.14.3)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /anaconda3/lib/python3.6/site-packages (0.22.0)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.6/site-packages (from pandas) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2 in /anaconda3/lib/python3.6/site-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /anaconda3/lib/python3.6/site-packages (from pandas) (1.14.3)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.6/site-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /anaconda3/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /anaconda3/lib/python3.6/site-packages (from matplotlib) (1.14.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda3/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda3/lib/python3.6/site-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda3/lib/python3.6/site-packages (from matplotlib) (2.7.3)\n",
      "Requirement already satisfied: pytz in /anaconda3/lib/python3.6/site-packages (from matplotlib) (2018.4)\n",
      "Requirement already satisfied: six>=1.10 in /anaconda3/lib/python3.6/site-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda3/lib/python3.6/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (39.1.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /anaconda3/lib/python3.6/site-packages (from sklearn) (0.19.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/KK/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\" \n",
    "Im sorry that Jaume and I picked up a rather quick pace during the bootcamp\n",
    "We hope this commentary would enable you to understand this python script better\n",
    "Please do not hesitate to email machinelearning@lsesu.org should you have any problems\n",
    "Anyways, lets begin writing our code\n",
    "\n",
    "For the very first step, we download the libraries relevant to our task.\n",
    "The symbol \"!\" informs python that such function is to be called out from terminal /command line\n",
    "\"\"\"\"\"\n",
    "! pip3 install numpy\n",
    "! pip3 install pandas\n",
    "! pip3 install matplotlib\n",
    "! pip3 install sklearn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "We name our dataset as \"data\" and call out the read_csv() function from our pandas package\n",
    "The input in the pd.read() function is your fil e path\n",
    "P.S. Remember to add in quotational marks to denote your path as a string!\n",
    "\"\"\"\"\"\n",
    "data = pd.read_csv('Data/data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/KK/Documents/LSE/Personal-Projects'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 786)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "Now we check the shape of our data. You will realize this dataset is a (6000 x 786) matrix\n",
    "This means we have 6000 samples and 784 variables in our dataset (note 28*28 = 784!)\n",
    "\"\"\"\"\"\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  0  1  2  3  4  5  6  7  8 ...   775  776  777  778  779  780  \\\n",
       "0           0  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "1           1  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "2           2  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "3           3  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "4           4  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "\n",
       "   781  782  783  784  \n",
       "0    0    0    0    5  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    4  \n",
       "3    0    0    0    1  \n",
       "4    0    0    0    9  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "The head() function shows users the first few rows of their dataset\n",
    "This enables users to understand how the dataset is structured\n",
    "\"\"\"\"\"\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "1. We have 60000 images\n",
    "2. Images are 28*28\n",
    "3. We have a column with the labels: 0,1,2,3,...,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Instead of having an additional index column, we replace it using the first column of our dataset\n",
    "Note that in Python, it uses 0 indexing format, meaning it counts from 0 instead of 1.\n",
    "Hence here, data.columns[0] denotes the first column of our dataset\n",
    "\"\"\"\"\"\n",
    "data = data.set_index(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "As expected, once we replace the index with one column, the number of columns reduces from 786 to 785\n",
    "\"\"\"\"\"\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will only use 5000 rows of the data\n",
    "sample = data.sample(frac=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "The iloc[] command enables us to extract a subset within our dataset\n",
    "sample.iloc[:,:-1] means we extract all rows and all columns (except for the last one!) of the dataset\n",
    "sample.iloc[:,-1] ? Well you can easily guess it. This means we extract all rows and only the last column\n",
    "For econometricians / statisticians, you can think about the last column as \"y\" and all other columns being the feature\n",
    "set \"X\"\n",
    "\"\"\"\"\"\n",
    "# separate images and labels\n",
    "images = sample.iloc[:,:-1]\n",
    "labels = sample.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59049</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39287</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46683</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  1  2  3  4  5  6  7  8  9 ...   774  775  776  777  778  779  \\\n",
       "Unnamed: 0                               ...                                  \n",
       "6007        0  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "59049       0  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "45392       0  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "39287       0  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "46683       0  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0   \n",
       "\n",
       "            780  781  782  783  \n",
       "Unnamed: 0                      \n",
       "6007          0    0    0    0  \n",
       "59049         0    0    0    0  \n",
       "45392         0    0    0    0  \n",
       "39287         0    0    0    0  \n",
       "46683         0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "Again, the head function allows you to glimpse through your dataset\n",
    "\"\"\"\"\"\n",
    "images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "def f(): is the basic format of defining our own function in Python. I will not go through the function here\n",
    "as it as not particularly relevant to ML. This function simply allows you to visualize your data\n",
    "\"\"\"\"\"\n",
    "def show_digit(image):\n",
    "    \"\"\"Image: (784,1) np array\n",
    "    \"\"\"\n",
    "    \n",
    "    digit = image.reshape(28,28)\n",
    "    plt.imshow(digit, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    }
   ],
   "source": [
    "# look up digit\n",
    "num = 12\n",
    "show_digit(images.values[num,:])\n",
    "print('Label: ' + str(labels.values[num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for Training\n",
    "\n",
    "SVMs are a linear programming model so we need to:\n",
    "\n",
    "1. Have the training data in Matrix Format\n",
    "2. Separate the training set into validation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Now we define our X (feature set) and y (outcome)\n",
    "We use images.values instead of images to drop the index\n",
    "\"\"\"\"\"\n",
    "X = images.values\n",
    "y = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 784), (6000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "Again, we review the shape of our matrix. Unsurprisingly, X has 784 columns (x1,x2...,x784) \n",
    "and y has only one column (a vector)\n",
    "\"\"\"\"\"\n",
    "X.shape, y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "In the very beginning of this script, we imported the function \"train_test_split()\" from sklearn.model_selection\n",
    "As we emphasized during the bootcamp, these packages have built in functions that could facilitate our analysis\n",
    "and we don't necessarily have to define our own function tediously\n",
    "\n",
    "To reiterate, in Machine Learning, we are concerned about Out-of-Sample predictions. Hence, we partition our dataset\n",
    "into train data and test data. (I tend to think of this as \"pretending\" that the test data is unseen data)\n",
    "\"\"\"\"\"\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4800, 784), (1200, 784), (4800,), (1200,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "You should know by now what the shape function does\n",
    "\"\"\"\"\"\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "\n",
    "1. Train the model on the training set\n",
    "2. Hypertune the SVM parameters on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Here we select our model as SVC. There are many other models other than the support vector classifier within sklearn\n",
    "such as RandomForestClassifier()/ linear_model.lasso etc. Who knows, maybe you can learn about these alternative models\n",
    "in our second bootcamp ;)\n",
    "\n",
    "We also need to choose the kernel (Think of this as the shape of the decision boundary). Other kernels we discussed \n",
    "during the bootcamp includes Gaussian(RBF), polynomial boundaries etc. Feel free to try them out yourself by inputting\n",
    "model = SVC(kernel = 'poly',degree=2) or model = SVC()    --> The default kernel is the Gaussian kernel\n",
    "\n",
    "\"\"\"\"\"\n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "The fit function simply fits your model with your data. Again, we only fit our training data as we pretend that \n",
    "it is the only available dataset. We will later on apply this model to our test data to compute the model's accuracy\n",
    "\"\"\"\"\"\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "This helps you find the coefficients of the model and the support vectors of the SVC\n",
    "\"\"\"\"\"\n",
    "\n",
    "coefs = model.dual_coef_\n",
    "supports = model.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 1683), (1683, 784))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.shape, supports.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 784 dimensional space, the support vectors are the data points that generate a 1 vs 1 hyperplane to separate a ovservations of 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "This function shows you the prediction output (yval_predicted) corresponding to your testing Xval\n",
    "\"\"\"\"\"\n",
    "def train(m, Xtrain, ytrain, Xval):\n",
    "    \"\"\" model: sklearn model\n",
    "    \"\"\"\n",
    "    m.fit(Xtrain, ytrain)\n",
    "    predictions = m.predict(Xval)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = train(SVC(kernel='linear'), X_train, y_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 3, ..., 7, 4, 7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "Show the prediction results\n",
    "\"\"\"\"\"\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91583333333333339"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "In sklearn.metrics, there exists a built in function that compares your predicted results with true results\n",
    "It will display the % of correct predictions\n",
    "\"\"\"\"\"\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   0   1   0   1   0   0   0   0   1]\n",
      " [  0 150   0   1   1   1   0   1   4   1]\n",
      " [  1   1  92   3   1   3   2   2   4   0]\n",
      " [  1   0   2 113   0   3   0   0   7   3]\n",
      " [  0   0   2   0 126   1   1   1   0   6]\n",
      " [  0   0   1   4   0  81   2   0   4   0]\n",
      " [  0   0   1   0   0   3 106   0   0   0]\n",
      " [  0   0   1   0   0   0   0 122   0   5]\n",
      " [  2   0   3   3   0   1   1   0 102   1]\n",
      " [  0   0   0   2   6   0   0   5   0 100]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "confusion_matrix is also a built in function within sklearn\n",
    "The diagonal of the matrix shows the number of observations predicted correctly within a particular class (digits)\n",
    "\n",
    "\"\"\"\"\"\n",
    "cm = confusion_matrix(pred, y_val)\n",
    "print(cm)\n",
    "\n",
    "\"\"\"\"\"\n",
    "The following is simply a fancier way present the confusion matrix\n",
    "it may make things slightly more confusing (Pun intended) so I will not go through the steps\n",
    "\"\"\"\"\"\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "ticks = np.arange(10)\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertuning and CV\n",
    "Improve the accuracy of our model without overfitting. We can do 2 things:\n",
    "\n",
    "1. Choose what type of regularization to use\n",
    "2. Hypertune model complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "As mentioned during the bootcamp. Most pannel data is not linearly separable and even if they are, fitting a \n",
    "hard margin may not necessarily yield the best results (Remember Bias Variance Trade-off!)\n",
    "\n",
    "Intuition: The hard margin hyperplane could change dramatically if you select a different sample from the same \n",
    "population. This means your model will have an extremely high variance!\n",
    "\n",
    "To reconcile this, we allow for some slacks in our classification, meaning some data points will be misclassified\n",
    "but this could reduce our model's variance dramatically\n",
    "\n",
    "In our SVC function, C denotes the amount of \"slack\" you allow for. The higher the value of C, the more lineant \n",
    "your model is\n",
    "\n",
    "Notice previously, we simply typed in SVC(kernel='linear') without actually keying in C. Sklearn defaults\n",
    "C as 1 if you do not manually type in C.\n",
    "\"\"\"\"\"\n",
    "pred = train(SVC(kernel='linear', C=0.000000001), X_train, y_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33833333333333332"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "As you can expect, if you set C = 0.00000001 (meaning you're a jackass who doesn't allow for much error), the\n",
    "prediction result would be significant lower due to the model's high variance\n",
    "\"\"\"\"\"\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-10   5.45559478e-10   2.97635144e-09   1.62377674e-08\n",
      "   8.85866790e-08   4.83293024e-07   2.63665090e-06   1.43844989e-05\n",
      "   7.84759970e-05   4.28133240e-04   2.33572147e-03   1.27427499e-02\n",
      "   6.95192796e-02   3.79269019e-01   2.06913808e+00   1.12883789e+01\n",
      "   6.15848211e+01   3.35981829e+02   1.83298071e+03   1.00000000e+04]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "Here, we call out the logspace function from our numpy library\n",
    "There are 3 key arguments in this function. \n",
    "The 1st is your starting value of the sequence, 2nd is the final value of the sequence, and 3rd is the number\n",
    "of samples to generate\n",
    "\n",
    "So we generate an array containing 20 numbers ranging from 10^-10 to 10^4 spaced evenly\n",
    "\"\"\"\"\"\n",
    "log_C = np.logspace(-10,4, 20)\n",
    "print(log_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Here, we introduce the for loop\n",
    "The for loop is an essential tool in Python that enables you to iterate the same process on different objects\n",
    "continuously\n",
    "\n",
    "In this loop, we show our accuracy score corresponding to different values of C we generated previously using the \n",
    "logspace() function\n",
    "\n",
    "\"\"\"\"\"\n",
    "\n",
    "accs = []\n",
    "for c in log_C:\n",
    "    prd = train(LinearSVC(C=c), X_train, y_train, X_val)\n",
    "    acc = accuracy_score(prd, y_val)\n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74916666666666665, 0.79333333333333333, 0.84999999999999998, 0.8783333333333333, 0.89500000000000002, 0.90000000000000002, 0.88500000000000001, 0.87666666666666671, 0.8666666666666667, 0.85166666666666668, 0.84583333333333333, 0.84999999999999998, 0.84750000000000003, 0.84666666666666668, 0.84916666666666663, 0.85333333333333339, 0.84999999999999998, 0.85250000000000004, 0.84416666666666662, 0.84583333333333333]\n"
     ]
    }
   ],
   "source": [
    "print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Among the accs list, we choose the c that yields the highest accuracy score and define it as best_C\n",
    "\"\"\"\"\"\n",
    "best_C = log_C[np.argmax(accs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.832930238571752e-07"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Knowing our optimal C, we can train our SVC model again using C = best_C\n",
    "\"\"\"\"\"\n",
    "\n",
    "prd = train(SVC(kernel='linear', C=best_C), X_train, y_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9291666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "Comparing the results here, you should (hopefully) get a higher accuracy score!\n",
    "\"\"\"\"\"\n",
    "accuracy_score(prd, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "We use the cross-validation score to evaluate whether this is the best model\n",
    "np.concatenate() simply concatenates your X_train and X_val datasets\n",
    "\"\"\"\"\"\n",
    "scores = cross_val_score(SVC(kernel='linear', C=best_C), np.concatenate([X_train, \n",
    "    X_val]), np.concatenate([y_train, y_val]), cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.91347754,  0.91347754,  0.91666667,  0.91916667,  0.92558528]),\n",
       " 0.9176747384978956)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Complexity tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "Visualizing the complexity tradeoff\n",
    "Here we define errors as 1 - x for x in accs (the list containing accuracy score corresponsing to different Cs)\n",
    "because error = 1 - accuracy\n",
    "We use the \"C\" which yields the lowest Mean-Squared-Error (global minima of this graph)\n",
    "\"\"\"\"\"\n",
    "\n",
    "errors = [1.0 - x for x in accs]\n",
    "plt.plot(log_C, errors)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearch Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-10,   5.45559e-10,   2.97635e-09,   1.62378e-08,\n",
       "         8.85867e-08,   4.83293e-07,   2.63665e-06,   1.43845e-05,\n",
       "         7.84760e-05,   4.28133e-04,   2.33572e-03,   1.27427e-02,\n",
       "         6.95193e-02,   3.79269e-01,   2.06914e+00,   1.12884e+01,\n",
       "         6.15848e+01,   3.35982e+02,   1.83298e+03,   1.00000e+04])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C':log_C}\n",
    "model = grid_search.GridSearchCV(SVC(kernel='linear'), parameters)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=4.832930238571752e-07, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# what is the best model?\n",
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
